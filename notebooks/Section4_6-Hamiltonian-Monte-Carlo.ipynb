{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Hamiltonian Monte Carlo"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Introduction to Mathematical Expressions with Theano\n",
      "\n",
      "Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Theano features:\n",
      "\n",
      "* __tight integration with numpy__ \u2013 Use numpy.ndarray in Theano-compiled functions.\n",
      "* __transparent use of a GPU__ \u2013 Perform data-intensive calculations up to 140x faster than with CPU.(float32 only)\n",
      "* __efficient symbolic differentiation__ \u2013 Theano does your derivatives for function with one or many inputs.\n",
      "* __speed and stability optimizations__ \u2013 Get the right answer for log(1+x) even when x is really tiny.\n",
      "* __dynamic C code generation__ \u2013 Evaluate expressions faster.\n",
      "* __extensive unit-testing and self-verification__ \u2013 Detect and diagnose many types of mistake.\n",
      "\n",
      "### Installing Theano\n",
      "\n",
      "The easiest way to install Theano is to build it from source, using **pip**:\n",
      "\n",
      "    pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Adding Two Scalars\n",
      "\n",
      "To get us started with Theano and get a feel of what we're working with, \n",
      "let's make a simple function: add two numbers together. Here is how you do\n",
      "it:\n",
      "\n",
      "### Step 1 - Declaring Variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano import function, shared\n",
      "from theano import tensor as T\n",
      "import theano\n",
      "\n",
      "x = T.dscalar('x')\n",
      "y = T.dscalar('y')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In Theano, all symbols must be typed. In particular, `T.dscalar`\n",
      "is the type we assign to \"0-dimensional arrays (`scalar`) of doubles\n",
      "(`d`)\". It is a Theano `type`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(x)\n",
      "print x.type\n",
      "print T.dscalar\n",
      "print x.type is T.dscalar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'theano.tensor.var.TensorVariable'>\n",
        "TensorType(float64, scalar)\n",
        "TensorType(float64, scalar)\n",
        "True\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 2 - Symbolic Expressions\n",
      "\n",
      "The second step is to combine *x* and *y* into their sum *z*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z = x + y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*z* is yet another *Variable* which represents the addition of\n",
      "*x* and *y*. You can use the `pp` function to *pretty-print* out the computation associated to *z*.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano.printing import pp\n",
      "print pp(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(x + y)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 3 - Compiling a Function\n",
      "\n",
      "The last step is to create a function taking *x* and *y* as inputs\n",
      "and giving *z* as output:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = function([x, y], z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first argument to `function()` is a list of Variables\n",
      "that will be provided as inputs to the function. The second argument\n",
      "is a single Variable *or* a list of Variables. For either case, the second\n",
      "argument is what we want to see as output when we apply the function. *f* may\n",
      "then be used like a normal Python function.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can call the function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print f(2, 3)\n",
      "print f(16.3, 12.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.0\n",
        "28.4\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you are following along and typing into an interpreter, you may have\n",
      "noticed that there was a slight delay in executing the ``function``\n",
      "instruction. Behind the scene, *f* was being compiled into C code."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Note on Symbolic Variables:\n",
      "\n",
      "A *Variable* is the main data structure you work with when\n",
      "using Theano. The symbolic inputs that you operate on are\n",
      "*Variables* and what you get from applying various operations to\n",
      "these inputs are also *Variables*. For example, when I type\n",
      "\"`x = theano.tensor.ivector(); y = -x`\" then *x* and *y* are both Variables, i.e. instances of the\n",
      "``theano.gof.graph.Variable`` class. The\n",
      "type of both *x* and *y* is ``theano.tensor.ivector``.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By calling `T.dscalar` with a string argument, you create a\n",
      "`Variable` representing a floating-point scalar quantity with the\n",
      "given name. If you provide no argument, the symbol will be unnamed. Names\n",
      "are not required, but they can help debugging."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Adding Two Matrices\n",
      "\n",
      "If we want to work with matrices instead of scalars, the only change\n",
      "from the previous example is that you need to instantiate *x* and\n",
      "*y* using the matrix Types:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = T.dmatrix('x')\n",
      "y = T.dmatrix('y')\n",
      "z = x + y\n",
      "f = function([x, y], z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``dmatrix`` is the Type for matrices of doubles. Then we can use\n",
      "our new function on 2D arrays:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f([[1, 2], [3, 4]], [[10, 20], [30, 40]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[ 11.,  22.],\n",
        "       [ 33.,  44.]])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following types are available:\n",
      "\n",
      "* **byte**: ``bscalar, bvector, bmatrix, brow, bcol, btensor3, btensor4``\n",
      "* **16-bit integers**: ``wscalar, wvector, wmatrix, wrow, wcol, wtensor3, wtensor4``\n",
      "* **32-bit integers**: ``iscalar, ivector, imatrix, irow, icol, itensor3, itensor4``\n",
      "* **64-bit integers**: ``lscalar, lvector, lmatrix, lrow, lcol, ltensor3, ltensor4``\n",
      "* **float**: ``fscalar, fvector, fmatrix, frow, fcol, ftensor3, ftensor4``\n",
      "* **double**: ``dscalar, dvector, dmatrix, drow, dcol, dtensor3, dtensor4``\n",
      "* **complex**: ``cscalar, cvector, cmatrix, crow, ccol, ctensor3, ctensor4``"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An example of a slightly more interesting function is the logistic curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = T.dmatrix('x')\n",
      "s = 1 / (1 + T.exp(-x))\n",
      "logistic = function([x], s)\n",
      "print logistic([[0, 1], [-1, -2]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.5         0.73105858]\n",
        " [ 0.26894142  0.11920292]]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Computing More than one Thing at the Same Time\n",
      "\n",
      "Theano supports functions with multiple outputs. For example, we can\n",
      "compute the elementwise difference, absolute difference, and\n",
      "squared difference between two matrices *a* and *b* at the same time.\n",
      "\n",
      "When we use the function `f`, it returns the three computed results as a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a, b = T.dmatrices('a', 'b')\n",
      "diff = a - b\n",
      "abs_diff = abs(diff)\n",
      "diff_squared = diff ** 2\n",
      "\n",
      "f = function([a, b], [diff, abs_diff, diff_squared])\n",
      "\n",
      "print f([[1, 1], [1, 1]], [[0, 1], [2, 3]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([[ 1.,  0.],\n",
        "       [-1., -2.]]), array([[ 1.,  0.],\n",
        "       [ 1.,  2.]]), array([[ 1.,  0.],\n",
        "       [ 1.,  4.]])]\n"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Setting a Default Value for an Argument\n",
      " \n",
      "Let's say you want to define a function that adds two numbers, except\n",
      "that if you only provide one number, the other input is assumed to be\n",
      "one. In Python, the default value for parameters achieves this effect.\n",
      "In Theano you can achieve this effect with a `Param` object.\n",
      "\n",
      "This makes use of the <a href=\"http://deeplearning.net/software/theano/library/compile/io.html#function-inputs\">Param</a> class which allows\n",
      "you to specify properties of your function's parameters with greater detail. Here we\n",
      "give a default value of 1 for *y* by creating a ``Param`` instance with\n",
      "its ``default`` field set to 1. Inputs with default values must follow inputs without default\n",
      "values (like Python's functions).  There can be multiple inputs with default values. These parameters can\n",
      "be set positionally or by name, as in standard Python."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -- Theano version of lambda x, y=1: x + y\n",
      "\n",
      "from theano import Param\n",
      "x, y = T.dscalars('x', 'y')\n",
      "z = x + y\n",
      "f = function([x, Param(y, default=1)], z)\n",
      "\n",
      "print f(33)\n",
      "print f(33, 2)\n",
      "print f(34)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "34.0\n",
        "35.0\n",
        "35.0\n"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -- Theano version of lambda x, y=1, w_by_name=2: (x + y) * w\n",
      "x, y, w = T.dscalars('x', 'y', 'w')\n",
      "z = (x + y) * w\n",
      "g = function([x, Param(y, default=1), Param(w, default=2, name='w_by_name')], z)\n",
      "print g(33)\n",
      "print g(33, 2)\n",
      "print g(33, 0, 1)\n",
      "print g(33, w_by_name=1)\n",
      "print g(33, w_by_name=1, y=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "68.0\n",
        "70.0\n",
        "33.0\n",
        "34.0\n",
        "33.0\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Maintaining State with Shared Variables\n",
      "\n",
      "It is also possible to make a function with an internal state. For example, let\u2019s say we want to make an accumulator: at the beginning, the state is initialized to zero. Then, on each function call, the state is incremented by the function\u2019s argument.\n",
      "\n",
      "First let\u2019s define the accumulator function. It adds its argument to the internal state, and returns the old state value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state = shared(0)\n",
      "inc = T.iscalar('inc')\n",
      "accumulator = function([inc], state, updates=[(state, state+inc)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code introduces a few new concepts. The shared function constructs so-called shared variables. These are hybrid symbolic and non-symbolic variables whose value may be shared between multiple functions. Shared variables can be used in symbolic expressions just like the objects returned by dmatrices(...) but they also have an internal value that defines the value taken by this symbolic variable in all the functions that use it. It is called a shared variable because its value is shared between many functions. The value can be accessed and modified by the .get_value() and .set_value() methods. We will come back to this soon.\n",
      "\n",
      "The other new thing in this code is the updates parameter of function. updates must be supplied with a list of pairs of the form (shared-variable, new expression). It can also be a dictionary whose keys are shared-variables and values are the new expressions. Either way, it means \u201cwhenever this function runs, it will replace the .value of each shared variable with the result of the corresponding expression\u201d. Above, our accumulator replaces the state\u2018s value with the sum of the state and the increment amount.\n",
      "\n",
      "Let\u2019s try it out!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print state.get_value()\n",
      "print accumulator(1)\n",
      "print state.get_value()\n",
      "print accumulator(300)\n",
      "print state.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "0\n",
        "1\n",
        "1\n",
        "301\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to reset the state. Just use the .set_value() method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state.set_value(-1)\n",
      "print accumulator(3)\n",
      "print state.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we mentioned above, you can define more than one function to use the same shared variable. These functions can all update the value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "decrementor = function([inc], state, updates=[(state, state-inc)])\n",
      "print decrementor(2)\n",
      "print state.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "301\n",
        "299\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You might be wondering why the updates mechanism exists. You can always achieve a similar result by returning the new expressions, and working with them in NumPy as usual. While the updates mechanism can be a syntactic convenience, it is mainly there for *efficiency*. Updates to shared variables can sometimes be done more quickly using in-place algorithms (e.g. low-rank matrix updates). Also, Theano has more control over where and how shared variables are allocated, which is one of the important elements of getting good performance on the GPU.\n",
      "\n",
      "### Example: Logistic regression\n",
      "\n",
      "Here is a non-trivial example, which uses Theano to estimate the parameters of a logistic regression mdoel using gradient information. We will use the bioassay example as a test case:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "rng = np.random\n",
      "\n",
      "dose = np.array([-0.86, -0.3 , -0.05,  0.73])\n",
      "deaths = np.array([0, 1, 3, 5])\n",
      "training_steps = 1000\n",
      "\n",
      "# Declare Theano symbolic variables\n",
      "x = T.vector(\"x\")\n",
      "y = T.vector(\"y\")\n",
      "w = theano.shared(1., name=\"w\")\n",
      "b = theano.shared(0., name=\"b\")\n",
      "print \"Initial model:\"\n",
      "print w.get_value(), b.get_value()\n",
      "\n",
      "# Construct Theano expression graph\n",
      "p_1 = 1 / (1 + T.exp(-(x*w + b)))   # Probability that target = 1\n",
      "prediction = p_1 > 0.5                    # The prediction thresholded\n",
      "xent = -y * T.log(p_1) - (5-y) * T.log(1-p_1) # Cross-entropy loss function\n",
      "cost = xent.mean() # The cost to minimize\n",
      "gw,gb = T.grad(cost, [w, b])              # Compute the gradient of the cost\n",
      "                                          # (we shall return to this in a\n",
      "                                          # following section of this tutorial)\n",
      "\n",
      "# Compile\n",
      "step = theano.shared(10., name='step')\n",
      "train = theano.function(\n",
      "          inputs=[x, y],\n",
      "          outputs=[prediction, xent],\n",
      "          updates=((w, w - step * gw), (b, b - step * gb), (step, step * 0.99)))\n",
      "predict = theano.function(inputs=[x], outputs=prediction)\n",
      "\n",
      "# Train\n",
      "for i in range(training_steps):\n",
      "    pred, err = train(dose, deaths)\n",
      "\n",
      "print \"Final model:\"\n",
      "print w.get_value(), b.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initial model:\n",
        "1.0 0.0\n",
        "Final model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7.79515245754 0.853642024968\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit = lambda x: 1. / (1 + np.exp(-x))\n",
      "xvals = np.linspace(-1, 1)\n",
      "plt.plot(xvals, logit(7*xvals + .9))\n",
      "plt.plot(dose, deaths/5., 'ro')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "[<matplotlib.lines.Line2D at 0x112aa4b90>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAECCAYAAAAb5qc/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11261d350>"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hamiltonian Monte Carlo\n",
      "\n",
      "Maximum likelihood learning of energy-based models requires a robust\n",
      "algorithm to sample negative phase particles. When training RBMs with CD or PCD, this is\n",
      "typically done with block Gibbs sampling, where the conditional\n",
      "distributions $p(h|v)$ and $p(v|h)$ are used as the transition operators\n",
      "of the Markov chain.\n",
      "\n",
      "In certain cases however, these conditional distributions might be\n",
      "difficult to sample from (i.e. requiring expensive matrix inversions, as\n",
      "in the case of the \"mean-covariance RBM\"). Also, even if Gibbs sampling\n",
      "can be done efficiently, it nevertheless operates via a random walk\n",
      "which might not be statistically efficient for some distributions. In\n",
      "this context, and when sampling from continuous variables, Hamiltonian (or Hybrid) Monte\n",
      "Carlo (HMC) can prove to be a powerful tool. It avoids\n",
      "random walk behavior by simulating a physical system governed by\n",
      "Hamiltonian dynamics, potentially avoiding tricky conditional\n",
      "distributions in the process.\n",
      "\n",
      "In HMC, model samples are obtained by simulating a physical system,\n",
      "where particles move about a high-dimensional landscape, subject to\n",
      "potential and kinetic energies. Adapting the notation from [Neal (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html),\n",
      "particles are characterized by a position vector or state\n",
      "$s \\in \\mathcal{R}^D$ and velocity vector $\\phi \\in \\mathcal{R}^D$. The\n",
      "combined state of a particle is denoted as $\\chi=(s,\\pi)$. The\n",
      "Hamiltonian is then defined as the sum of potential energy $E(s)$ (same\n",
      "energy function defined by energy-based models) and kinetic energy\n",
      "$K(\\phi)$, as follows:\n",
      "\n",
      "$$\\mathcal{H}(s,\\phi) = E(s) + K(\\phi)\n",
      "= E(s) + \\frac{1}{2} \\sum_i \\phi_i^2$$\n",
      "\n",
      "Instead of sampling $p(s)$ directly, HMC operates by sampling from the\n",
      "canonical distribution\n",
      "$p(s,\\phi) = \\frac{1}{Z} \\exp(-\\mathcal{H}(s,\\phi))=p(s)p(\\phi)$.\n",
      "Because the two variables are independent, marginalizing over $\\phi$ is\n",
      "trivial and recovers the original distribution of interest.\n",
      "\n",
      "**Hamiltonian Dynamics**\n",
      "\n",
      "State $s$ and velocity $\\phi$ are modified such that\n",
      "$\\mathcal{H}(s,\\phi)$ remains constant throughout the simulation. The\n",
      "differential equations are given by:\n",
      "\n",
      "$$\\begin{aligned}\\frac{ds_i}{dt} &= \\frac{\\partial \\mathcal{H}}{\\partial \\phi_i} = \\phi_i \\\\\n",
      "\\frac{d\\phi_i}{dt} &= - \\frac{\\partial \\mathcal{H}}{\\partial s_i}\n",
      "= - \\frac{\\partial E}{\\partial s_i}\n",
      "\\end{aligned}$$\n",
      "\n",
      "As shown in [Neal (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html), \n",
      "the above transformation preserves volume and is\n",
      "reversible. The above dynamics can thus be used as transition operators\n",
      "of a Markov chain and will leave $p(s,\\phi)$ invariant. That chain by\n",
      "itself is not ergodic however, since simulating the dynamics maintains a\n",
      "fixed Hamiltonian $\\mathcal{H}(s,\\phi)$. HMC thus alternates hamiltonian\n",
      "dynamic steps, with Gibbs sampling of the velocity. Because $p(s)$ and\n",
      "$p(\\phi)$ are independent, sampling $\\phi_{new} \\sim p(\\phi|s)$ is\n",
      "trivial since $p(\\phi|s)=p(\\phi)$, where $p(\\phi)$ is often taken to be\n",
      "the uni-variate Gaussian.\n",
      "\n",
      "**The Leap-Frog Algorithm**\n",
      "\n",
      "In practice, we cannot simulate Hamiltonian dynamics exactly because of\n",
      "the problem of time discretization. There are several ways one can do\n",
      "this. To maintain invariance of the Markov chain however, care must be\n",
      "taken to preserve the properties of volume conservation and time\n",
      "reversibility. The **leap-frog algorithm** maintains these properties\n",
      "and operates in 3 steps:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "\\phi_i(t + \\epsilon/2) &= \\phi_i(t) - \\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t)) \\\\\n",
      "s_i(t + \\epsilon) &= s_i(t) + \\epsilon \\phi_i(t + \\epsilon/2) \\\\\n",
      "\\phi_i(t + \\epsilon) &= \\phi_i(t + \\epsilon/2) - \\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t + \\epsilon)) \n",
      "\\end{aligned}$$\n",
      "\n",
      "We thus perform a half-step update of the velocity at time\n",
      "$t+\\epsilon/2$, which is then used to compute $s(t + \\epsilon)$ and\n",
      "$\\phi(t + \\epsilon)$.\n",
      "\n",
      "**Accept / Reject**\n",
      "\n",
      "In practice, using finite stepsizes $\\epsilon$ will not preserve\n",
      "$\\mathcal{H}(s,\\phi)$ exactly and will introduce bias in the simulation.\n",
      "Also, rounding errors due to the use of floating point numbers means\n",
      "that the above transformation will not be perfectly reversible.\n",
      "\n",
      "HMC cancels these effects **exactly** by adding a Metropolis\n",
      "accept/reject stage, after $n$ leapfrog steps. The new state\n",
      "$\\chi' = (s',\\phi')$ is accepted with probability $p_{acc}(\\chi,\\chi')$,\n",
      "defined as:\n",
      "\n",
      "$$p_{acc}(\\chi,\\chi') = min \\left( 1, \\frac{\\exp(-\\mathcal{H}(s',\\phi')}{\\exp(-\\mathcal{H}(s,\\phi)} \\right)$$\n",
      "\n",
      "**HMC Algorithm**\n",
      "\n",
      "We obtain a new HMC sample as follows:\n",
      "\n",
      "1.  sample a new velocity from a univariate Gaussian distribution\n",
      "2.  perform $n$ leapfrog steps to obtain the new state $\\chi'$\n",
      "3.  perform accept/reject move of $\\chi'$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implementing HMC Using Theano\n",
      "-----------------------------\n",
      "\n",
      "In Theano, update dictionaries and shared variables provide a natural\n",
      "way to implement a sampling algorithm. The current state of the sampler\n",
      "can be represented as a Theano shared variable, with HMC updates being\n",
      "implemented by the updates list of a Theano function.\n",
      "\n",
      "We breakdown the HMC algorithm into the following sub-components:\n",
      "\n",
      "-   `simulate_dynamics`: a symbolic Python function which, given an\n",
      "    initial position and velocity, will perform `n_steps` leapfrog\n",
      "    updates and return the symbolic variables for the proposed state\n",
      "    $\\chi'$.\n",
      "-   `hmc_move`: a symbolic Python function which given a starting\n",
      "    position, generates $\\chi$ by randomly sampling a velocity vector.\n",
      "    It then calls `simulate_dynamics` and determines whether the\n",
      "    transition $\\chi\n",
      "    \\rightarrow \\chi'$ is to be accepted.\n",
      "-   `hmc_updates`: a Python function which, given the symbolic\n",
      "    outputs of `hmc_move`, generates the list of updates for a single\n",
      "    iteration of HMC.\n",
      "-   `HMC_sampler`: a Python helper class which wraps everything\n",
      "    together.\n",
      "\n",
      "**simulate\\_dynamics**\n",
      "\n",
      "To perform $n$ leapfrog steps, we first need to define a function over\n",
      "which `Scan` can iterate over. Instead of implementing Eq.\n",
      ":eq:`leap-frog` verbatim, notice that we can obtain\n",
      "$s(t + n \\epsilon)$ and $\\phi(t + n \\epsilon)$ by performing an initial\n",
      "half-step update for $\\phi$, followed by $n$ full-step updates for\n",
      "$s,\\phi$ and one last half-step update for $\\phi$. In loop form, this\n",
      "gives:\n",
      "\n",
      "$$\\begin{aligned}\\phi_i(t + \\epsilon/2) &= \\phi_i(t) -\n",
      "\\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t)) \\\\\n",
      "s_i(t + \\epsilon) &= s_i(t) + \\epsilon \\phi_i(t + \\epsilon/2) \\\\\n",
      "\\text{For } m \\in [2,n]\\text{, perform full updates: } \\\\\n",
      "\\qquad\n",
      "\\phi_i(t + (m - 1/2)\\epsilon) &= \\phi_i(t + (m-3/2)\\epsilon) -\n",
      "\\epsilon \\frac{\\partial{}}{\\partial s_i} E(s(t + (m-1)\\epsilon)) \\\\\n",
      "\\qquad\n",
      "s_i(t + m\\epsilon) &= s_i(t) + \\epsilon \\phi_i(t + (m-1/2)\\epsilon) \\\\\n",
      "\\phi_i(t + n\\epsilon) &= \\phi_i(t + (n-1/2)\\epsilon) -\n",
      "\\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t + n\\epsilon)) \n",
      "\\end{aligned}$$\n",
      "\n",
      "The inner-loop defined above is implemented by the following\n",
      "`leapfrog` function, with `pos`, `vel` and `step` replacing\n",
      "$s,\\phi$ and $\\epsilon$ respectively."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def leapfrog(pos, vel, step):\n",
      "    \"\"\"\n",
      "    Inside loop of Scan. Performs one step of leapfrog update, using\n",
      "    Hamiltonian dynamics.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    pos: theano matrix\n",
      "        in leapfrog update equations, represents pos(t), position at time t\n",
      "    vel: theano matrix\n",
      "        in leapfrog update equations, represents vel(t - stepsize/2),\n",
      "        velocity at time (t - stepsize/2)\n",
      "    step: theano scalar\n",
      "        scalar value controlling amount by which to move\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    rval1: [theano matrix, theano matrix]\n",
      "        Symbolic theano matrices for new position pos(t + stepsize), and\n",
      "        velocity vel(t + stepsize/2)\n",
      "    rval2: List of (variable, update expr) pairs\n",
      "        List of updates for the Scan Op\n",
      "    \"\"\"\n",
      "    # from pos(t) and vel(t - eps/2), compute vel(t + eps / 2)\n",
      "    dE_dpos = TT.grad(energy_fn(pos).sum(), pos)\n",
      "    new_vel = vel - step * dE_dpos\n",
      "    # from vel(t + eps / 2) compute pos(t + eps)\n",
      "    new_pos = pos + step * new_vel\n",
      "\n",
      "    return [new_pos, new_vel],{}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `simulate_dynamics` function performs the full algorithm. We start with the initial half-step update of $\\phi$\n",
      "and full-step of $s$, and then scan over the `leapfrog` method `n_steps-1` times."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def simulate_dynamics(initial_pos, initial_vel, stepsize, n_steps, energy_fn):\n",
      "    \"\"\"\n",
      "    Return final (position, velocity) obtained after an `n_steps` leapfrog\n",
      "    updates, using Hamiltonian dynamics.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    initial_pos: shared theano matrix\n",
      "        Initial position at which to start the simulation\n",
      "    initial_vel: shared theano matrix\n",
      "        Initial velocity of particles\n",
      "    stepsize: shared theano scalar\n",
      "        Scalar value controlling amount by which to move\n",
      "    energy_fn: python function\n",
      "        Python function, operating on symbolic theano variables, used to\n",
      "        compute the potential energy at a given position.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    rval1: theano matrix\n",
      "        Final positions obtained after simulation\n",
      "    rval2: theano matrix\n",
      "        Final velocity obtained after simulation\n",
      "    \"\"\"\n",
      "\n",
      "    def leapfrog(pos, vel, step):\n",
      "        \"\"\"\n",
      "        Inside loop of Scan. Performs one step of leapfrog update, using\n",
      "        Hamiltonian dynamics.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        pos: theano matrix\n",
      "            in leapfrog update equations, represents pos(t), position at time t\n",
      "        vel: theano matrix\n",
      "            in leapfrog update equations, represents vel(t - stepsize/2),\n",
      "            velocity at time (t - stepsize/2)\n",
      "        step: theano scalar\n",
      "            scalar value controlling amount by which to move\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        rval1: [theano matrix, theano matrix]\n",
      "            Symbolic theano matrices for new position pos(t + stepsize), and\n",
      "            velocity vel(t + stepsize/2)\n",
      "        rval2: dictionary\n",
      "            Dictionary of updates for the Scan Op\n",
      "        \"\"\"\n",
      "        # from pos(t) and vel(t-stepsize/2), compute vel(t+stepsize/2)\n",
      "        dE_dpos = T.grad(energy_fn(pos).sum(), pos)\n",
      "        new_vel = vel - step * dE_dpos\n",
      "        # from vel(t+stepsize/2) compute pos(t+stepsize)\n",
      "        new_pos = pos + step * new_vel\n",
      "        return [new_pos, new_vel], {}\n",
      "\n",
      "    # compute velocity at time-step: t + stepsize/2\n",
      "    initial_energy = energy_fn(initial_pos)\n",
      "    dE_dpos = T.grad(initial_energy.sum(), initial_pos)\n",
      "    vel_half_step = initial_vel - 0.5 * stepsize * dE_dpos\n",
      "\n",
      "    # compute position at time-step: t + stepsize\n",
      "    pos_full_step = initial_pos + stepsize * vel_half_step\n",
      "\n",
      "    # perform leapfrog updates: the scan op is used to repeatedly compute\n",
      "    # vel(t + (m-1/2)*stepsize) and pos(t + m*stepsize) for m in [2,n_steps].\n",
      "    (all_pos, all_vel), scan_updates = theano.scan(leapfrog,\n",
      "            outputs_info=[\n",
      "                dict(initial=pos_full_step),\n",
      "                dict(initial=vel_half_step),\n",
      "                ],\n",
      "            non_sequences=[stepsize],\n",
      "            n_steps=n_steps - 1)\n",
      "    final_pos = all_pos[-1]\n",
      "    final_vel = all_vel[-1]\n",
      "    # NOTE: Scan always returns an updates dictionary, in case the\n",
      "    # scanned function draws samples from a RandomStream. These\n",
      "    # updates must then be used when compiling the Theano function, to\n",
      "    # avoid drawing the same random numbers each time the function is\n",
      "    # called. In this case however, we consciously ignore\n",
      "    # \"scan_updates\" because we know it is empty.\n",
      "    assert not scan_updates\n",
      "\n",
      "    # The last velocity returned by scan is vel(t +\n",
      "    # (n_steps - 1 / 2) * stepsize) We therefore perform one more half-step\n",
      "    # to return vel(t + n_steps * stepsize)\n",
      "    energy = energy_fn(final_pos)\n",
      "    final_vel = final_vel - 0.5 * stepsize * T.grad(energy.sum(), final_pos)\n",
      "\n",
      "    # return new proposal state\n",
      "    return final_pos, final_vel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A final half-step is performed to compute $\\phi(t+n\\epsilon)$, and the\n",
      "final proposed state $\\chi'$ is returned.\n",
      "\n",
      "**hmc_move**\n",
      "\n",
      "The `hmc_move` function implements the remaining steps (steps 1 and\n",
      "3) of an HMC move proposal (while wrapping the `simulate_dynamics`\n",
      "function). Given a matrix of initial states\n",
      "$s \\in \\mathcal{R}^{N \\times D}$ (`positions`) and energy function\n",
      "$E(s)$ (`energy_fn`), it defines the symbolic graph for computing\n",
      "`n_steps` of HMC, using a given `stepsize`. The function prototype\n",
      "is as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hmc_move(s_rng, positions, energy_fn, stepsize, n_steps):\n",
      "    \"\"\"\n",
      "    This function performs one-step of Hybrid Monte-Carlo sampling. We start by\n",
      "    sampling a random velocity from a univariate Gaussian distribution, perform\n",
      "    `n_steps` leap-frog updates using Hamiltonian dynamics and accept-reject\n",
      "    using Metropolis-Hastings.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    s_rng: theano shared random stream\n",
      "        Symbolic random number generator used to draw random velocity and\n",
      "        perform accept-reject move.\n",
      "    positions: shared theano matrix\n",
      "        Symbolic matrix whose rows are position vectors.\n",
      "    energy_fn: python function\n",
      "        Python function, operating on symbolic theano variables, used to\n",
      "        compute the potential energy at a given position.\n",
      "    stepsize:  shared theano scalar\n",
      "        Shared variable containing the stepsize to use for `n_steps` of HMC\n",
      "        simulation steps.\n",
      "    n_steps: integer\n",
      "        Number of HMC steps to perform before proposing a new position.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    rval1: boolean\n",
      "        True if move is accepted, False otherwise\n",
      "    rval2: theano matrix\n",
      "        Matrix whose rows contain the proposed \"new position\"\n",
      "    \"\"\"\n",
      "\n",
      "    # sample random velocity\n",
      "    initial_vel = s_rng.normal(size=positions.shape)\n",
      "\n",
      "    # perform simulation of particles subject to Hamiltonian dynamics\n",
      "    final_pos, final_vel = simulate_dynamics(\n",
      "            initial_pos=positions,\n",
      "            initial_vel=initial_vel,\n",
      "            stepsize=stepsize,\n",
      "            n_steps=n_steps,\n",
      "            energy_fn=energy_fn)\n",
      "\n",
      "    # accept/reject the proposed move based on the joint distribution\n",
      "    accept = metropolis_hastings_accept(\n",
      "            energy_prev=hamiltonian(positions, initial_vel, energy_fn),\n",
      "            energy_next=hamiltonian(final_pos, final_vel, energy_fn),\n",
      "            s_rng=s_rng)\n",
      "\n",
      "    return accept, final_pos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start by sampling random velocities, using the provided shared\n",
      "RandomStream object. Velocities are sampled independently for each\n",
      "dimension and for each particle under simulation, yielding a\n",
      "$N \\times D$ matrix.\n",
      "\n",
      "    initial_vel = s_rng.normal(size=positions.shape)\n",
      "    \n",
      "Since we now have an initial position and velocity, we can now call the\n",
      "`simulate_dynamics` to obtain the proposal for the new state $\\chi'$.\n",
      "\n",
      "    final_pos, final_vel = simulate_dynamics(\n",
      "            initial_pos = positions, \n",
      "            initial_vel = initial_vel,\n",
      "            stepsize = stepsize,\n",
      "            n_steps = n_steps,\n",
      "            energy_fn = energy_fn)\n",
      "            \n",
      "We then accept/reject the proposed state based on the Metropolis\n",
      "algorithm.\n",
      "\n",
      "    accept = metropolis_hastings_accept(\n",
      "            energy_prev=hamiltonian(positions, initial_vel, energy_fn),\n",
      "            energy_next=hamiltonian(final_pos, final_vel, energy_fn),\n",
      "            s_rng=s_rng)\n",
      "            \n",
      "where `metropolis_hastings_accept` and `hamiltonian` are helper\n",
      "functions, defined as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def metropolis_hastings_accept(energy_prev, energy_next, s_rng):\n",
      "    \"\"\"\n",
      "    Performs a Metropolis-Hastings accept-reject move.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    energy_prev: theano vector\n",
      "        Symbolic theano tensor which contains the energy associated with the\n",
      "        configuration at time-step t.\n",
      "    energy_next: theano vector\n",
      "        Symbolic theano tensor which contains the energy associated with the\n",
      "        proposed configuration at time-step t+1.\n",
      "    s_rng: theano.tensor.shared_randomstreams.RandomStreams\n",
      "        Theano shared random stream object used to generate the random number\n",
      "        used in proposal.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    return: boolean\n",
      "        True if move is accepted, False otherwise\n",
      "    \"\"\"\n",
      "    ediff = energy_prev - energy_next\n",
      "    return (T.exp(ediff) - s_rng.uniform(size=energy_prev.shape)) >= 0\n",
      "\n",
      "\n",
      "def kinetic_energy(vel):\n",
      "    \"\"\"Returns the kinetic energy associated with the given velocity\n",
      "    and mass of 1.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    vel: theano matrix\n",
      "        Symbolic matrix whose rows are velocity vectors.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    return: theano vector\n",
      "        Vector whose i-th entry is the kinetic entry associated with vel[i].\n",
      "\n",
      "    \"\"\"\n",
      "    return 0.5 * (vel ** 2).sum(axis=1)\n",
      "\n",
      "\n",
      "def hamiltonian(pos, vel, energy_fn):\n",
      "    \"\"\"\n",
      "    Returns the Hamiltonian (sum of potential and kinetic energy) for the given\n",
      "    velocity and position.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    pos: theano matrix\n",
      "        Symbolic matrix whose rows are position vectors.\n",
      "    vel: theano matrix\n",
      "        Symbolic matrix whose rows are velocity vectors.\n",
      "    energy_fn: python function\n",
      "        Python function, operating on symbolic theano variables, used tox\n",
      "        compute the potential energy at a given position.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    return: theano vector\n",
      "        Vector whose i-th entry is the Hamiltonian at position pos[i] and\n",
      "        velocity vel[i].\n",
      "    \"\"\"\n",
      "    # assuming mass is 1\n",
      "    return energy_fn(pos) + kinetic_energy(vel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`hmc_move` finally returns the tuple `(accept, final_pos)`.\n",
      "`accept` is a symbolic boolean variable indicating whether or not the\n",
      "new state `final_pos` should be used or not.\n",
      "\n",
      "**hmc_updates**\n",
      "\n",
      "The purpose of `hmc_updates` is to generate the list of updates to\n",
      "perform, whenever our HMC sampling function is called. `hmc_updates`\n",
      "thus receives as parameters, a series of shared variables to update\n",
      "(`positions`, `stepsize` and `avg_acceptance_rate`), and the\n",
      "parameters required to compute their new state.\n",
      "\n",
      "    def hmc_updates(positions, stepsize, avg_acceptance_rate, final_pos, \n",
      "            accept, target_acceptance_rate, stepsize_inc, stepsize_dec, \n",
      "            stepsize_min, stepsize_max, avg_acceptance_slowness):\n",
      "    \n",
      "    \n",
      "        accept_matrix = accept.dimshuffle(0, *(('x',) * (final_pos.ndim - 1)))\n",
      "        \n",
      "        new_positions = T.switch(accept_matrix, final_pos, positions)\n",
      "        \n",
      "Using the above code, the dictionary `{positions: new_positions}` can\n",
      "be used to update the state of the sampler with either (1) the new state\n",
      "`final_pos` if `accept` is True, or (2) the old state if `accept`\n",
      "is False. This conditional assignment is performed by the\n",
      "[switch](http://deeplearning.net/software/theano/library/tensor/basic.html#tensor.switch)\n",
      "op.\n",
      "\n",
      "`switch` expects as its first argument, a boolean mask with the same\n",
      "broadcastable dimensions as the second and third argument. Since\n",
      "`accept` is scalar-valued, we must first use\n",
      "[dimshuffle](http://deeplearning.net/software/theano/library/tensor/basic.html#tensor._tensor_py_operators.dimshuffle)\n",
      "to transform it to a tensor with `final_pos.ndim` broadcastable\n",
      "dimensions (`accept_matrix`).\n",
      "\n",
      "`hmc_updates` additionally implements an adaptive version of HMC. We start by\n",
      "tracking the average acceptance rate of the HMC move proposals (across\n",
      "many simulations), using an exponential moving average with time\n",
      "constant `1-avg_acceptance_slowness`.\n",
      "\n",
      "    new_acceptance_rate = T.add(\n",
      "            avg_acceptance_slowness * avg_acceptance_rate,\n",
      "            (1.0 - avg_acceptance_slowness) * accept.mean())\n",
      "            \n",
      "If the average acceptance rate is larger than the\n",
      "`target_acceptance_rate`, we increase the `stepsize` by a factor\n",
      "of `stepsize_inc` in order to increase the mixing rate of our chain.\n",
      "If the average acceptance rate is too low however, `stepsize` is\n",
      "decreased by a factor of `stepsize_dec`, yielding a more conservative\n",
      "mixing rate. The\n",
      "[clip](http://deeplearning.net/software/theano/library/tensor/basic.html#tensor.clip)\n",
      "op allows us to maintain the `stepsize` in the range\n",
      "[`stepsize_min`, `stepsize_max`].\n",
      "\n",
      "    _new_stepsize = TT.switch(avg_acceptance_rate > target_acceptance_rate,\n",
      "                              stepsize * stepsize_inc, stepsize * stepsize_dec)\n",
      "    # maintain stepsize in [stepsize_min, stepsize_max]\n",
      "    new_stepsize = TT.clip(_new_stepsize, stepsize_min, stepsize_max)\n",
      "\n",
      "The final updates list is then returned:\n",
      "\n",
      "    return [(positions, new_positions),\n",
      "        (stepsize, new_stepsize),\n",
      "        (avg_acceptance_rate, new_acceptance_rate)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hmc_updates(positions, stepsize, avg_acceptance_rate, final_pos, accept,\n",
      "                 target_acceptance_rate, stepsize_inc, stepsize_dec,\n",
      "                 stepsize_min, stepsize_max, avg_acceptance_slowness):\n",
      "    \"\"\"This function is executed after `n_steps` of HMC sampling\n",
      "    (`hmc_move` function). It creates the updates dictionary used by\n",
      "    the `simulate` function. It takes care of updating: the position\n",
      "    (if the move is accepted), the stepsize (to track a given target\n",
      "    acceptance rate) and the average acceptance rate (computed as a\n",
      "    moving average).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    positions: shared variable, theano matrix\n",
      "        Shared theano matrix whose rows contain the old position\n",
      "    stepsize: shared variable, theano scalar\n",
      "        Shared theano scalar containing current step size\n",
      "    avg_acceptance_rate: shared variable, theano scalar\n",
      "        Shared theano scalar containing the current average acceptance rate\n",
      "    final_pos: shared variable, theano matrix\n",
      "        Shared theano matrix whose rows contain the new position\n",
      "    accept: theano scalar\n",
      "        Boolean-type variable representing whether or not the proposed HMC move\n",
      "        should be accepted or not.\n",
      "    target_acceptance_rate: float\n",
      "        The stepsize is modified in order to track this target acceptance rate.\n",
      "    stepsize_inc: float\n",
      "        Amount by which to increment stepsize when acceptance rate is too high.\n",
      "    stepsize_dec: float\n",
      "        Amount by which to decrement stepsize when acceptance rate is too low.\n",
      "    stepsize_min: float\n",
      "        Lower-bound on `stepsize`.\n",
      "    stepsize_min: float\n",
      "        Upper-bound on `stepsize`.\n",
      "    avg_acceptance_slowness: float\n",
      "        Average acceptance rate is computed as an exponential moving average.\n",
      "        (1-avg_acceptance_slowness) is the weight given to the newest\n",
      "        observation.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    rval1: dictionary-like\n",
      "        A dictionary of updates to be used by the `HMC_Sampler.simulate`\n",
      "        function.  The updates target the position, stepsize and average\n",
      "        acceptance rate.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    ## POSITION UPDATES ##\n",
      "    # broadcast `accept` scalar to tensor with the same dimensions as\n",
      "    # final_pos.\n",
      "    accept_matrix = accept.dimshuffle(0, *(('x',) * (final_pos.ndim - 1)))\n",
      "    # if accept is True, update to `final_pos` else stay put\n",
      "    new_positions = T.switch(accept_matrix, final_pos, positions)\n",
      "\n",
      "    ## STEPSIZE UPDATES ##\n",
      "    # if acceptance rate is too low, our sampler is too \"noisy\" and we reduce\n",
      "    # the stepsize. If it is too high, our sampler is too conservative, we can\n",
      "    # get away with a larger stepsize (resulting in better mixing).\n",
      "    _new_stepsize = T.switch(avg_acceptance_rate > target_acceptance_rate,\n",
      "                              stepsize * stepsize_inc, stepsize * stepsize_dec)\n",
      "    # maintain stepsize in [stepsize_min, stepsize_max]\n",
      "    new_stepsize = T.clip(_new_stepsize, stepsize_min, stepsize_max)\n",
      "\n",
      "    ## ACCEPT RATE UPDATES ##\n",
      "    # perform exponential moving average\n",
      "    mean_dtype = theano.scalar.upcast(accept.dtype, avg_acceptance_rate.dtype)\n",
      "    new_acceptance_rate = T.add(\n",
      "            avg_acceptance_slowness * avg_acceptance_rate,\n",
      "            (1.0 - avg_acceptance_slowness) * accept.mean(dtype=mean_dtype))\n",
      "\n",
      "    return [(positions, new_positions),\n",
      "            (stepsize, new_stepsize),\n",
      "            (avg_acceptance_rate, new_acceptance_rate)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**HMC_sampler**\n",
      "\n",
      "We finally tie everything together using the `HMC_Sampler` class. Its\n",
      "main elements are:\n",
      "\n",
      "-   `new_from_shared_positions`: a constructor method which\n",
      "    allocates various shared variables and strings together the calls to\n",
      "    `hmc_move` and `hmc_updates`. It also builds the theano\n",
      "    function `simulate`, whose sole purpose is to execute the updates\n",
      "    generated by `hmc_updates`.\n",
      "-   `draw`: a convenience method which calls the Theano function\n",
      "    `simulate` and returns a copy of the contents of the shared\n",
      "    variable `self.positions`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sharedX = lambda X, name: \\\n",
      "        shared(numpy.asarray(X, dtype=theano.config.floatX), name=name)\n",
      "\n",
      "class HMC_sampler(object):\n",
      "    \"\"\"\n",
      "    Convenience wrapper for performing Hybrid Monte Carlo (HMC). It creates the\n",
      "    symbolic graph for performing an HMC simulation (using `hmc_move` and\n",
      "    `hmc_updates`). The graph is then compiled into the `simulate` function, a\n",
      "    theano function which runs the simulation and updates the required shared\n",
      "    variables.\n",
      "\n",
      "    Users should interface with the sampler thorugh the `draw` function which\n",
      "    advances the markov chain and returns the current sample by calling\n",
      "    `simulate` and `get_position` in sequence.\n",
      "\n",
      "    The hyper-parameters are the same as those used by Marc'Aurelio's\n",
      "    'train_mcRBM.py' file (available on his personal home page).\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, **kwargs):\n",
      "        self.__dict__.update(kwargs)\n",
      "\n",
      "    @classmethod\n",
      "    def new_from_shared_positions(cls, shared_positions, energy_fn,\n",
      "            initial_stepsize=0.01, target_acceptance_rate=.9, n_steps=20,\n",
      "            stepsize_dec=0.98,\n",
      "            stepsize_min=0.001,\n",
      "            stepsize_max=0.25,\n",
      "            stepsize_inc=1.02,\n",
      " # used in geometric avg. 1.0 would be not moving at all\n",
      "            avg_acceptance_slowness=0.9,\n",
      "            seed=12345):\n",
      "        \"\"\"\n",
      "        :param shared_positions: theano ndarray shared var with\n",
      "            many particle [initial] positions\n",
      "\n",
      "        :param energy_fn:\n",
      "            callable such that energy_fn(positions)\n",
      "            returns theano vector of energies.\n",
      "            The len of this vector is the batchsize.\n",
      "\n",
      "            The sum of this energy vector must be differentiable (with\n",
      "            theano.tensor.grad) with respect to the positions for HMC\n",
      "            sampling to work.\n",
      "\n",
      "        \"\"\"\n",
      "        batchsize = shared_positions.shape[0]\n",
      "\n",
      "        # allocate shared variables\n",
      "        stepsize = sharedX(initial_stepsize, 'hmc_stepsize')\n",
      "        avg_acceptance_rate = sharedX(target_acceptance_rate,\n",
      "                                      'avg_acceptance_rate')\n",
      "        s_rng = T.shared_randomstreams.RandomStreams(seed)\n",
      "\n",
      "        # define graph for an `n_steps` HMC simulation\n",
      "        accept, final_pos = hmc_move(\n",
      "                s_rng,\n",
      "                shared_positions,\n",
      "                energy_fn,\n",
      "                stepsize,\n",
      "                n_steps)\n",
      "\n",
      "        # define the dictionary of updates, to apply on every `simulate` call\n",
      "        simulate_updates = hmc_updates(\n",
      "                shared_positions,\n",
      "                stepsize,\n",
      "                avg_acceptance_rate,\n",
      "                final_pos=final_pos,\n",
      "                accept=accept,\n",
      "                stepsize_min=stepsize_min,\n",
      "                stepsize_max=stepsize_max,\n",
      "                stepsize_inc=stepsize_inc,\n",
      "                stepsize_dec=stepsize_dec,\n",
      "                target_acceptance_rate=target_acceptance_rate,\n",
      "                avg_acceptance_slowness=avg_acceptance_slowness)\n",
      "\n",
      "        # compile theano function\n",
      "        simulate = function([], [], updates=simulate_updates)\n",
      "\n",
      "        # create HMC_sampler object with the following attributes ...\n",
      "        return cls(\n",
      "                positions=shared_positions,\n",
      "                stepsize=stepsize,\n",
      "                stepsize_min=stepsize_min,\n",
      "                stepsize_max=stepsize_max,\n",
      "                avg_acceptance_rate=avg_acceptance_rate,\n",
      "                target_acceptance_rate=target_acceptance_rate,\n",
      "                s_rng=s_rng,\n",
      "                _updates=simulate_updates,\n",
      "                simulate=simulate)\n",
      "\n",
      "    def draw(self, **kwargs):\n",
      "        \"\"\"\n",
      "        Returns a new position obtained after `n_steps` of HMC simulation.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        kwargs: dictionary\n",
      "            The `kwargs` dictionary is passed to the shared variable\n",
      "            (self.positions) `get_value()` function.  For example, to avoid\n",
      "            copying the shared variable value, consider passing `borrow=True`.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        rval: numpy matrix\n",
      "            Numpy matrix whose of dimensions similar to `initial_position`.\n",
      "       \"\"\"\n",
      "        self.simulate()\n",
      "        return self.positions.get_value(borrow=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Testing our Sampler\n",
      "\n",
      "We test our implementation of HMC by sampling from a multi-variate\n",
      "Gaussian distribution. We start by generating a random mean vector\n",
      "`mu` and covariance matrix `cov`, which allows us to define the\n",
      "energy function of the corresponding Gaussian distribution:\n",
      "`gaussian_energy`. We then initialize the state of the sampler by\n",
      "allocating a `position` shared variable. It is passed to the\n",
      "constructor of `HMC_sampler` along with our target energy function.\n",
      "\n",
      "Following a burn-in period, we then generate a large number of samples\n",
      "and compare the empirical mean and covariance matrix to their true\n",
      "values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sampler_on_nd_gaussian(sampler_cls, burnin, n_samples, dim=10):\n",
      "    batchsize=3\n",
      "\n",
      "    rng = np.random.RandomState(123)\n",
      "\n",
      "    # Define a covariance and mu for a gaussian\n",
      "    mu  = np.array(rng.rand(dim) * 10, dtype=theano.config.floatX)\n",
      "    cov = np.array(rng.rand(dim, dim), dtype=theano.config.floatX)\n",
      "    cov = (cov + cov.T) / 2.\n",
      "    cov[numpy.arange(dim), numpy.arange(dim)] = 1.0\n",
      "    cov_inv = linalg.inv(cov)\n",
      "\n",
      "    # Define energy function for a multi-variate Gaussian\n",
      "    def gaussian_energy(x):\n",
      "        return 0.5 * (TT.dot((x - mu), cov_inv) * (x - mu)).sum(axis=1)\n",
      "\n",
      "    # Declared shared random variable for positions\n",
      "    position = shared(rng.randn(batchsize, dim).astype(theano.config.floatX))\n",
      "\n",
      "    # Create HMC sampler\n",
      "    sampler = sampler_cls(position, gaussian_energy,\n",
      "            initial_stepsize=1e-3, stepsize_max=0.5)\n",
      "\n",
      "    # Start with a burn-in process\n",
      "    garbage = [sampler.draw() for r in xrange(burnin)]  #burn-in\n",
      "    # Draw `n_samples`: result is a 3D tensor of dim [n_samples, batchsize, dim]\n",
      "    _samples = np.asarray([sampler.draw() for r in xrange(n_samples)])\n",
      "    # Flatten to [n_samples * batchsize, dim]\n",
      "    samples = _samples.T.reshape(dim, -1).T\n",
      "\n",
      "    print '****** TARGET VALUES ******'\n",
      "    print 'target mean:', mu\n",
      "    print 'target cov:\\n', cov\n",
      "\n",
      "    print '****** EMPIRICAL MEAN/COV USING HMC ******'\n",
      "    print 'empirical mean: ', samples.mean(axis=0)\n",
      "    print 'empirical_cov:\\n', np.cov(samples.T)\n",
      "\n",
      "    print '****** HMC INTERNALS ******'\n",
      "    print 'final stepsize', sampler.stepsize.get_value()\n",
      "    print 'final acceptance_rate', sampler.avg_acceptance_rate.get_value()\n",
      "\n",
      "    return sampler\n",
      "\n",
      "def test_hmc():\n",
      "    sampler = sampler_on_nd_gaussian(HMC_sampler.new_from_shared_positions,\n",
      "            burnin=1000, n_samples=1000, dim=5)\n",
      "    assert abs(sampler.avg_acceptance_rate.get_value() - sampler.target_acceptance_rate) < .1\n",
      "    assert sampler.stepsize.get_value() >= sampler.stepsize_min\n",
      "    assert sampler.stepsize.get_value() <= sampler.stepsize_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_hmc()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "****** TARGET VALUES ******\n",
        "target mean: [ 6.96469186  2.86139335  2.26851454  5.51314769  7.1946897 ]\n",
        "target cov:\n",
        "[[ 1.          0.66197111  0.71141257  0.55766643  0.35753822]\n",
        " [ 0.66197111  1.          0.31053199  0.45455485  0.37991646]\n",
        " [ 0.71141257  0.31053199  1.          0.62800335  0.38004541]\n",
        " [ 0.55766643  0.45455485  0.62800335  1.          0.50807871]\n",
        " [ 0.35753822  0.37991646  0.38004541  0.50807871  1.        ]]\n",
        "****** EMPIRICAL MEAN/COV USING HMC ******\n",
        "empirical mean:  [ 6.94155164  2.81526039  2.26301715  5.46536853  7.19414496]\n",
        "empirical_cov:\n",
        "[[ 1.05152997  0.68393537  0.76038645  0.59930252  0.37478746]\n",
        " [ 0.68393537  0.97708159  0.37351422  0.48362404  0.3839558 ]\n",
        " [ 0.76038645  0.37351422  1.03797111  0.67342957  0.41529132]\n",
        " [ 0.59930252  0.48362404  0.67342957  1.02865056  0.53613649]\n",
        " [ 0.37478746  0.3839558   0.41529132  0.53613649  0.98721449]]\n",
        "****** HMC INTERNALS ******\n",
        "final stepsize 0.460446628091\n",
        "final acceptance_rate 0.922502043428\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As can be seen above, the samples generated by our HMC sampler yield an\n",
      "empirical mean and covariance matrix, which are very close to the true\n",
      "underlying parameters. The adaptive algorithm also seemed to work well\n",
      "as the final acceptance rate is close to our target of `0.9`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## References\n",
      "\n",
      "[DeepLearning documentation and tutorials](http://deeplearning.net/tutorial/contents.html)\n",
      "\n",
      "[Neal, R.M. (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html) Probabilistic Inference Using Markov Chain Monte Carlo Methods, Technical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto, 144 pages.\n",
      "\n",
      "[Neal, R.M. (2011)](http://arxiv.org/abs/1206.1901) MCMC using Hamiltonian dynamics. Chapter 5 of the Handbook of Markov Chain Monte Carlo Edited by Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng\n",
      "Chapman & Hall / CRC Press."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width: 90%;\n",
        "/*        margin-left:auto;*/\n",
        "/*        margin-right:auto;*/\n",
        "    }\n",
        "    ul {\n",
        "        line-height: 145%;\n",
        "        font-size: 90%;\n",
        "    }\n",
        "    li {\n",
        "        margin-bottom: 1em;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top: 12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width: 90%;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "\n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x10907c690>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}